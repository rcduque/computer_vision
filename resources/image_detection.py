# -*- coding: utf-8 -*-
"""computer_vision.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yxrPr0x75SUzFogSwKx-CWinpyxaR6QW
"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow
from scipy import ndimage

img = cv2.imread('banano6.jpg') #read image
#img = cv2.imread('000078.jpg')

#images histogram
import matplotlib.pyplot as plt

black_with = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
vector = black_with.flatten()
plt.hist(vector, bins= 100)

#red = 0
plt.hist(img[:,:,0].flatten(), bins= 100, color='red')
#green = 1
plt.hist(img[:,:,1].flatten(), bins= 100, color='green')
#blue
plt.hist(img[:,:,2].flatten(), bins= 100, color='blue')

#umbral = 220 #set manual umbral
umbral, _ = cv2.threshold(black_with,0,255, cv2.THRESH_OTSU) #detect the umbral
mask = np.uint8((black_with < umbral)*255) # if hte color is grather than umbral set it as  white (255)
print(umbral)
cv2_imshow(mask)

#categorize images
output = cv2.connectedComponentsWithStats(mask, 4, cv2.CV_32S) #binary image, labels, stats 
num_objects = output[0] #number of objects
labels = output[1] #labels
stats = output[2] #stats

#get the label  with higher value exclidding the first one  = np.argmax(stats[:,4][1:])
#focused_image = np.uint8( (np.argmax(stats[:,4][1:])+1 == labels)) * 255 
focused_image = (np.argmax(stats[:,4][1:])+1 == labels)
focused_image = ndimage.binary_fill_holes(focused_image).astype(int) #fill holes with 1 o 0
focused_image = np.uint8(focused_image * 255) #set black and white
cv2_imshow(focused_image)

#Find area y perimeter
#only support 8bits
contours, hierarchy = cv2.findContours(focused_image,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)
contour = contours[0]

perimetro = cv2.arcLength(contour, True)
area = cv2.contourArea(contour)
print(perimetro)
print(area)

#Sum  pixeles
num_pixels = np.sum(focused_image)/255
print(num_pixels)

#Convex hull - poligono de area o limiacion que engloba varios puntos
hull = cv2.convexHull(contour) #taking into account the contour
convez_area = hull[:,0:]
convex_image = np.zeros(focused_image.shape) #create hte same matriz with 0s 
convex_image = cv2.fillConvexPoly(convex_image, convez_area,255) #fill the whole area
cv2_imshow(convex_image)

from collections import Counter
#BoundingBox
box_points = cv2.minAreaRect(contour) 
box = np.int0(cv2.boxPoints(box_points)) #get the recangle points 

box_image = np.zeros((convex_image.shape))
box_image = cv2.fillConvexPoly(box_image, box, 255 )

cv2_imshow(box_image)

x,y, w,h = cv2.boundingRect(contour)

#add rectanle in the image, 
#The image in the parameters will be overrided
#parametros x, y = coordenadas iniciales, w = ancho, h = alto
#color en rgb
rgb_color = (0,255,0)
line_width = 1 
cv2.rectangle(img, (x,y), (x+w, y+h), rgb_color,line_width)
cv2_imshow(img)

m = np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])
print(m.shape)
m[:,2] = 0
print(m)

#Draw contour
color_blue = (255,0,0)
cv2.drawContours(img, contour, -1, color_blue, 1)
cv2_imshow(img)

"""# **Filtros**



"""

#filtering with average 
filter_value = 10
depth = -1
kernel = np.ones((filter_value,filter_value), np.float)/(filter_value*filter_value)  #filtro
filtered_img = cv2.filter2D(img, depth , kernel)
cv2_imshow(filtered_img)

#Gaussian Filter
#img, kernel, y sigma = (desviación standar)
gaussian_img = cv2.GaussianBlur(img, (13,13), 10)
cv2_imshow(gaussian_img)

"""# **Border Detection**"""

a = np.zeros([100,50])
b = np.ones([100,50])
a[:,:] = 210
b[:,:] = 0
#img_border_detection = np.uint8(np.concatenate((a,b), axis=1))
img_border_detection = black_with

print(img_border_detection.shape)

gx = cv2.Sobel(img_border_detection, cv2.CV_64F, 1,0, 3)
gy = cv2.Sobel(img_border_detection, cv2.CV_64F, 0,1, 3)

magnitud, angulo = cv2.cartToPolar(gx,gy)

#get absolute value
gx = cv2.convertScaleAbs(gx)
gy = cv2.convertScaleAbs(gy)
magnitud = cv2.convertScaleAbs(magnitud)

#We must to change the angle for radians to degrees
angulo = (180/np.pi)*angulo

cv2_imshow(img_border_detection)
print(" ")
cv2_imshow(gx)
print(" ")
cv2_imshow(gy)
print(" ")
cv2_imshow(angulo)
print(" ")
cv2_imshow(magnitud)

#applying gaulaplaciano
img_gausian = cv2.GaussianBlur(black_with, (3,3),0) #difuminación gausiana
img_lap = cv2.convertScaleAbs( cv2.Laplacian(img_gausian, cv2.CV_64F, 3))

cv2_imshow(img_lap)

#With Canny detection
img_canny = cv2.Canny(black_with, 50, 150) #limite inferior/superior
#cv2_imshow(img_canny)

#Dilatar imagen, metodo para engrosar los bordes luego del paso Canny
kernel_1 = np.ones((5,5), np.uint8)
img_dilate = cv2.dilate(img_canny, kernel_1)
#cv2_imshow(img_dilate)

#find the contour
banano_contours, hierarchy = cv2.findContours(img_dilate,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)
objeto = img_dilate.copy()

#Convex hull - poligono de area o limiacion que engloba varios puntos

hull = cv2.convexHull(banano_contours[1]) 
convez_area = hull[:,0:]
convex_image = np.zeros(black_with.shape)
convex_image = cv2.fillConvexPoly(convex_image, convez_area,255)
#cv2_imshow(convex_image)

#cv2.drawContours(objeto, [max(hull, key=cv2.contourArea)], -1, 255, 1)
#cv2_imshow(objeto)
#objeto = objeto / 255
#objeto = convex_image.copy

print(convex_image)
convex_image = convex_image /255 
final_img = np.zeros(img.shape)
final_img[:,:,0] = np.uint8(convex_image * img[:,:,0])
final_img[:,:,1] = np.uint8(convex_image * img[:,:,1])
final_img[:,:,2] = np.uint8(convex_image * img[:,:,2])

final_img[:,:,0] = final_img[:,:,0] + (255 * (final_img[:,:,0]==255))
final_img[:,:,1] = final_img[:,:,1] + (255 * (final_img[:,:,1]==255))
final_img[:,:,2] = final_img[:,:,2] + (255 * (final_img[:,:,2]==255))

cv2_imshow(final_img)
cv2_imshow(img)

"""# **Homografia**"""

img = cv2.imread("cuadro.jpg")
#img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

#busquemos los puntos iniciales
m, n, _ = img.shape
puntos_source = np.array([[41,12],[193,50],[40,304],[198,271]])
putos_destination = np.array([[0,0],[n,0],[0,m],[n,m]])

homography, __ = cv2.findHomography(puntos_source, putos_destination)
img_homography = cv2.warpPerspective(img, homography, (n,m))

print(homography)

"""# **Ejercicio 1 - Calificador de Notas**"""

img = cv2.imread('foto_formato1.jpg') #read images

#find bordes
img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
img_canny = cv2.Canny(img_gray, 100, 150) #lower/upper limit 

# ** Dilate image, method to thicken the edges after the Canny step 
kernel_1 = np.ones((5,5), np.uint8)
img_dilate = cv2.dilate(img_canny, kernel_1, iterations=2)

#find cotour
img_contours, hierarchy = cv2.findContours(img_dilate,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)

#Find biggest area automatically
final_area = 0
max_area_index = 0
for i in range(len(img_contours)):
  area = cv2.contourArea(img_contours[i])
  if final_area < area :
    final_area = area
    max_area_index = i

# Find the convex hull object
hull = cv2.convexHull(img_contours[max_area_index])
hull_list = [hull]

# Find the convex hull object for each contour
#hull_list = []
#for i in range(len(img_contours)):
#  hull = cv2.convexHull(img_contours[i])
#  hull_list.append(hull)

#Rellenar
convex_image = np.zeros(img_gray.shape) 
for i in range(len(hull_list)):
  hull = hull_list[i]
  convex_image = cv2.fillConvexPoly(convex_image, hull,255) #fill area

#find image coordinates

#print(hull)
#print(hull[0][0][0]) #columna
#print(hull[0][0][1]) #fila

p1 = hull[0,0]
p2 = [900,900]
p3 = [0,900]
p4 = [0,0]


for i in range(len(hull)):
  #Find p1
  if hull[i][0][1] + hull[i][0][0] < p1[0] + p1[1]:
    p1 = hull[i][0]
  
  #Find p2
  if p2[0] > hull[i][0][0] and p2[1] < hull[i][0][1]:
    p2 = hull[i][0]   
  
  #Find p3
  if hull[i][0][0]- hull[i][0][1]> p3[0] - p3[1] :
    p3 = hull[i][0] 
  
  #Find p4
  if hull[i][0][0] +hull[i][0][1] > p4[1] + p4[0]:
    p4 = hull[i][0] 
  
##We can do it automatically with :
vertices = cv2.goodFeaturesToTrack(np.uint8(convex_image), 4, 0.01, 20) #imagen, numero de puntos, valor fijo, distancia entre puntnos

#cv2_imshow(convex_image)
#cv2_imshow(img_dilate)

#change perspective 
h, w, _ = img.shape
puntos_source = np.array([p1,p3,p2,p4])
putos_destination = np.array([[0,0],[w,0],[0,h],[w,h]])

homography, __ = cv2.findHomography(puntos_source, putos_destination)
img_homography = cv2.warpPerspective(img, homography, (w,h))

#cut image
area_interes = np.uint8(img_homography[:, np.uint64( w * 0.25 ): np.uint64( w * 0.85 )])
#cv2_imshow(area_interes)

opciones = ['A', 'B', 'C', 'D', 'E']
respuestas = []
preguntas = []

#26 is the umber of questions
question_row_size = np.uint64(h / 26 )
_, question_col_size, _ = area_interes.shape
question_col_size = np.uint64(question_col_size / 5 )



for i in range(26):  
  pregunta = (area_interes[ np.uint64(i*question_row_size) : np.uint64((i+1)* question_row_size),:])

  respuesta_value =  np.sum(pregunta)
  respues_index = 0
  sumI = []
  for j in range(5) :
    
    value = np.sum(pregunta[:, np.uint64(j*question_col_size) : np.uint64((j+1)* question_col_size)])
    
    if value < respuesta_value:
      respuesta_value = value
      respues_index = j

  respuestas.append(opciones[respues_index])

print(respuestas)
cv2_imshow(img)
#find the inerested image in a automatic way ** missing
"""
img_canny2 = cv2.Canny(img_homography, 1, 50)

white_rows = []
for i in range(h):
  white_rows.append(np.sum(img_canny2[i,:]))
  
print(white_rows)
#cv2_imshow(img_canny2)
"""